{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:iris.src.chat_model.model_settings:Using environment: local\n",
      "INFO:iris.src.chat_model.model_settings:Using API base URL: https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "# This enables auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import the model\n",
    "from iris.src.chat_model.model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversation for testing\n",
    "conversation = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in accounting.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What is the definition of a business combination under IFRS, search internal wiki only\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# You can modify the conversation above to test different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:iris.src.chat_model.model_settings:Using small model: gpt-4o-mini-2024-07-18 in local environment\n",
      "INFO:iris.src.chat_model.model_settings:Using large model: gpt-4o-2024-08-06 in local environment\n",
      "INFO:iris.src.chat_model.model_settings:Using small model: gpt-4o-mini-2024-07-18 in local environment\n",
      "INFO:iris.src.chat_model.model_settings:Using small model: gpt-4o-mini-2024-07-18 in local environment\n",
      "INFO:iris.src.chat_model.model_settings:Using small model: gpt-4o-mini-2024-07-18 in local environment\n",
      "INFO:iris.src.chat_model.model_settings:Using large model: gpt-4o-2024-08-06 in local environment\n",
      "2025-04-04 12:11:41,401 - root - INFO - Logging system initialized\n",
      "2025-04-04 12:11:41,401 - root - INFO - Initializing model setup...\n",
      "2025-04-04 12:11:41,401 - iris.src.initial_setup.ssl.ssl - INFO - SSL certificate setup skipped in local environment\n",
      "2025-04-04 12:11:41,401 - iris.src.initial_setup.oauth.oauth - INFO - Using API key authentication from local settings\n",
      "2025-04-04 12:11:41,401 - iris.src.initial_setup.oauth.oauth - INFO - Using OpenAI API key from settings: sk-proj...\n",
      "2025-04-04 12:11:41,401 - root - INFO - Processing input conversation...\n",
      "2025-04-04 12:11:41,401 - iris.src.conversation_setup.conversation - INFO - Processed conversation: 2 messages filtered to 1 messages\n",
      "2025-04-04 12:11:41,401 - root - INFO - Conversation processed: 1 messages\n",
      "2025-04-04 12:11:41,402 - root - INFO - Getting routing decision...\n",
      "2025-04-04 12:11:41,402 - iris.src.agents.agent_router.router - INFO - Getting routing decision using model: gpt-4o-mini-2024-07-18\n",
      "2025-04-04 12:11:41,420 - iris.src.llm_connectors.rbc_openai - INFO - Using API key: sk-proj...\n",
      "2025-04-04 12:11:41,420 - iris.src.llm_connectors.rbc_openai - INFO - Using API base URL: https://api.openai.com/v1\n",
      "2025-04-04 12:11:41,420 - iris.src.llm_connectors.rbc_openai - INFO - Making non-streaming call to model: gpt-4o-mini-2024-07-18 with tools in local environment\n",
      "2025-04-04 12:11:41,420 - iris.src.llm_connectors.rbc_openai - INFO - Attempt 1/3: Sending request to OpenAI API\n",
      "2025-04-04 12:11:41,421 - iris.src.llm_connectors.rbc_openai - INFO - API call parameters (excluding message content): {'model': 'gpt-4o-mini-2024-07-18', 'max_tokens': 4096, 'temperature': 0.0, 'stream': False, 'timeout': 30}\n",
      "2025-04-04 12:11:42,272 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 12:11:42,279 - iris.src.llm_connectors.rbc_openai - INFO - Received response in 0.86 seconds\n",
      "2025-04-04 12:11:42,279 - iris.src.llm_connectors.rbc_openai - INFO - Token usage - Completion: 9 ($0.0000), Prompt: 2362 ($0.0000), Total: 2371 tokens, Total Cost: $0.0000\n",
      "2025-04-04 12:11:42,280 - iris.src.agents.agent_router.router - INFO - Routing decision: research_from_database\n",
      "2025-04-04 12:11:42,280 - root - INFO - Using research path based on routing decision\n",
      "2025-04-04 12:11:42,281 - root - INFO - Clarifying research needs...\n",
      "2025-04-04 12:11:42,281 - iris.src.agents.agent_clarifier.clarifier - INFO - Clarifying research needs using model: gpt-4o-mini-2024-07-18\n",
      "2025-04-04 12:11:42,291 - iris.src.llm_connectors.rbc_openai - INFO - Using API key: sk-proj...\n",
      "2025-04-04 12:11:42,292 - iris.src.llm_connectors.rbc_openai - INFO - Using API base URL: https://api.openai.com/v1\n",
      "2025-04-04 12:11:42,292 - iris.src.llm_connectors.rbc_openai - INFO - Making non-streaming call to model: gpt-4o-mini-2024-07-18 with tools in local environment\n",
      "2025-04-04 12:11:42,293 - iris.src.llm_connectors.rbc_openai - INFO - Attempt 1/3: Sending request to OpenAI API\n",
      "2025-04-04 12:11:42,293 - iris.src.llm_connectors.rbc_openai - INFO - API call parameters (excluding message content): {'model': 'gpt-4o-mini-2024-07-18', 'max_tokens': 4096, 'temperature': 0.0, 'stream': False, 'timeout': 30}\n",
      "2025-04-04 12:11:43,462 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 12:11:43,465 - iris.src.llm_connectors.rbc_openai - INFO - Received response in 1.17 seconds\n",
      "2025-04-04 12:11:43,466 - iris.src.llm_connectors.rbc_openai - INFO - Token usage - Completion: 49 ($0.0000), Prompt: 2909 ($0.0000), Total: 2958 tokens, Total Cost: $0.0000\n",
      "2025-04-04 12:11:43,467 - iris.src.agents.agent_clarifier.clarifier - INFO - Clarifier decision: create_research_statement\n",
      "2025-04-04 12:11:43,467 - iris.src.agents.agent_clarifier.clarifier - INFO - Is continuation: False\n",
      "2025-04-04 12:11:43,468 - root - INFO - Creating research statement, proceeding with research\n",
      "2025-04-04 12:11:43,469 - root - INFO - Creating database query plan...\n",
      "2025-04-04 12:11:43,469 - iris.src.agents.agent_planner.planner - INFO - Creating query plan using model: gpt-4o-mini-2024-07-18\n",
      "2025-04-04 12:11:43,470 - iris.src.agents.agent_planner.planner - INFO - Is continuation: False\n",
      "2025-04-04 12:11:43,480 - iris.src.llm_connectors.rbc_openai - INFO - Using API key: sk-proj...\n",
      "2025-04-04 12:11:43,481 - iris.src.llm_connectors.rbc_openai - INFO - Using API base URL: https://api.openai.com/v1\n",
      "2025-04-04 12:11:43,482 - iris.src.llm_connectors.rbc_openai - INFO - Making non-streaming call to model: gpt-4o-mini-2024-07-18 with tools in local environment\n",
      "2025-04-04 12:11:43,483 - iris.src.llm_connectors.rbc_openai - INFO - Attempt 1/3: Sending request to OpenAI API\n",
      "2025-04-04 12:11:43,483 - iris.src.llm_connectors.rbc_openai - INFO - API call parameters (excluding message content): {'model': 'gpt-4o-mini-2024-07-18', 'max_tokens': 4096, 'temperature': 0.0, 'stream': False, 'timeout': 30}\n",
      "2025-04-04 12:11:46,262 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 12:11:46,265 - iris.src.llm_connectors.rbc_openai - INFO - Received response in 2.78 seconds\n",
      "2025-04-04 12:11:46,266 - iris.src.llm_connectors.rbc_openai - INFO - Token usage - Completion: 107 ($0.0000), Prompt: 3366 ($0.0000), Total: 3473 tokens, Total Cost: $0.0000\n",
      "2025-04-04 12:11:46,266 - iris.src.agents.agent_planner.planner - INFO - Query plan created with 2 queries\n",
      "2025-04-04 12:11:46,267 - root - INFO - Query plan created with 2 queries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "# üìã Research Plan\n",
      "\n",
      "## Research Statement\n",
      "Search the internal wiki for the definition of a business combination under IFRS, focusing on the relevant accounting treatment and any specific guidance provided in the RBC context.\n",
      "\n",
      "## Database Queries\n",
      "1. APG Wiki Entries: definition of business combination under IFRS and RBC guidance\n",
      "2. Corporate Accounting Policy Manuals: accounting treatment for business combinations under IFRS\n",
      "---\n",
      "\n",
      "\n",
      "## üîç Query 1: APG Wiki Entries - definition of business combination under IFRS and RBC guidance\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:11:46,268 - iris.src.agents.database_subagents.database_router - INFO - Routing query to database: internal_wiki\n",
      "2025-04-04 12:11:46,274 - iris.src.agents.database_subagents.internal_wiki.subagent - INFO - Querying Internal Wiki database: definition of business combination under IFRS and RBC guidance\n",
      "2025-04-04 12:11:46,274 - iris.src.chat_model.model_settings - INFO - Using large model: gpt-4o-2024-08-06 in local environment\n",
      "2025-04-04 12:11:46,275 - iris.src.agents.database_subagents.internal_wiki.subagent - INFO - Fetching wiki catalog with query: definition of business combination under IFRS and RBC guidance (environment: local)\n",
      "2025-04-04 12:11:46,298 - iris.src.agents.database_subagents.internal_wiki.subagent - INFO - Retrieved 3 catalog entries from database\n",
      "2025-04-04 12:11:46,299 - iris.src.agents.database_subagents.internal_wiki.subagent - INFO - Retrieved 3 catalog entries\n",
      "2025-04-04 12:11:46,299 - iris.src.agents.database_subagents.internal_wiki.subagent - INFO - Selecting relevant documents from catalog\n",
      "2025-04-04 12:11:46,300 - iris.src.chat_model.model_settings - INFO - Using small model: gpt-4o-mini-2024-07-18 in local environment\n",
      "2025-04-04 12:11:46,309 - iris.src.llm_connectors.rbc_openai - INFO - Using API key: sk-proj...\n",
      "2025-04-04 12:11:46,310 - iris.src.llm_connectors.rbc_openai - INFO - Using API base URL: https://api.openai.com/v1\n",
      "2025-04-04 12:11:46,310 - iris.src.llm_connectors.rbc_openai - INFO - Making non-streaming call to model: gpt-4o-mini-2024-07-18 in local environment\n",
      "2025-04-04 12:11:46,310 - iris.src.llm_connectors.rbc_openai - INFO - Attempt 1/3: Sending request to OpenAI API\n",
      "2025-04-04 12:11:46,310 - iris.src.llm_connectors.rbc_openai - INFO - API call parameters (excluding message content): {'model': 'gpt-4o-mini-2024-07-18', 'max_tokens': 200, 'temperature': 0.7, 'stream': False, 'timeout': 30}\n",
      "2025-04-04 12:11:46,877 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 12:11:46,880 - iris.src.llm_connectors.rbc_openai - INFO - Received response in 0.57 seconds\n",
      "2025-04-04 12:11:46,881 - iris.src.llm_connectors.rbc_openai - INFO - Token usage - Completion: 2 ($0.0000), Prompt: 371 ($0.0000), Total: 373 tokens, Total Cost: $0.0000 (Database: internal_wiki)\n",
      "2025-04-04 12:11:46,882 - iris.src.llm_connectors.rbc_openai - INFO - Updated token usage for database 'internal_wiki': 373 tokens\n",
      "2025-04-04 12:11:46,883 - iris.src.agents.database_subagents.internal_wiki.subagent - INFO - Selected document IDs: []\n",
      "2025-04-04 12:11:46,883 - iris.src.agents.database_subagents.internal_wiki.subagent - INFO - Selected 0 relevant documents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No relevant documents found in the Internal Wiki database. Please try refining your query or check other databases.\n",
      "\n",
      "---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:11:46,885 - root - INFO - Completed database query 1/2: internal_wiki\n",
      "2025-04-04 12:11:46,886 - iris.src.agents.agent_judge.judge - INFO - Evaluating research progress using model: gpt-4o-mini-2024-07-18\n",
      "2025-04-04 12:11:46,886 - iris.src.agents.agent_judge.judge - INFO - Completed queries: 1, Remaining queries: 1\n",
      "2025-04-04 12:11:46,897 - iris.src.llm_connectors.rbc_openai - INFO - Using API key: sk-proj...\n",
      "2025-04-04 12:11:46,898 - iris.src.llm_connectors.rbc_openai - INFO - Using API base URL: https://api.openai.com/v1\n",
      "2025-04-04 12:11:46,898 - iris.src.llm_connectors.rbc_openai - INFO - Making non-streaming call to model: gpt-4o-mini-2024-07-18 with tools in local environment\n",
      "2025-04-04 12:11:46,898 - iris.src.llm_connectors.rbc_openai - INFO - Attempt 1/3: Sending request to OpenAI API\n",
      "2025-04-04 12:11:46,899 - iris.src.llm_connectors.rbc_openai - INFO - API call parameters (excluding message content): {'model': 'gpt-4o-mini-2024-07-18', 'max_tokens': 4096, 'temperature': 0.0, 'stream': False, 'timeout': 30}\n",
      "2025-04-04 12:11:48,618 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 12:11:48,621 - iris.src.llm_connectors.rbc_openai - INFO - Received response in 1.72 seconds\n",
      "2025-04-04 12:11:48,622 - iris.src.llm_connectors.rbc_openai - INFO - Token usage - Completion: 75 ($0.0000), Prompt: 3358 ($0.0000), Total: 3433 tokens, Total Cost: $0.0000\n",
      "2025-04-04 12:11:48,622 - iris.src.agents.agent_judge.judge - INFO - Research decision: continue_research\n",
      "2025-04-04 12:11:48,623 - iris.src.agents.agent_judge.judge - INFO - Reason: The initial query results from the internal wiki are incomplete and do not provide a clear definition or guidance on business combinations under IFRS in the RBC context. The remaining query in the internal_capm database is essential to obtain authoritative policy statements regarding the accounting treatment for business combinations, which is a key aspect of the research statement....\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## üîç Query 2: Corporate Accounting Policy Manuals - accounting treatment for business combinations under IFRS\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:11:48,625 - iris.src.agents.database_subagents.database_router - INFO - Routing query to database: internal_capm\n",
      "2025-04-04 12:11:48,628 - iris.src.agents.database_subagents.internal_capm.subagent - INFO - Querying CAPM database: accounting treatment for business combinations under IFRS\n",
      "2025-04-04 12:11:49,132 - iris.src.agents.database_subagents.internal_capm.subagent - INFO - CAPM database query completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CENTRAL ACCOUNTING POLICY MANUAL RESULTS\n",
      "    \n",
      "    Query: accounting treatment for business combinations under IFRS\n",
      "    \n",
      "    The following policy guidelines were found:\n",
      "    \n",
      "    1. Policy Section PR-23.4: Accounting for Financial Instruments\n",
      "       - Classification and measurement requirements\n",
      "       - Recognition criteria for derivatives and embedded derivatives\n",
      "       - De-recognition principles for financial assets and liabilities\n",
      "    \n",
      "    2. Policy Section PR-14.7: Revenue Recognition Standards\n",
      "       - Five-step revenue recognition model\n",
      "       - Contract identification and modification guidance\n",
      "       - Performance obligation identification and fulfillment criteria\n",
      "    \n",
      "    3. Procedural Guidance PG-112: Implementation Examples\n",
      "       - Case studies for complex financial instruments\n",
      "       - Decision trees for classification challenges\n",
      "       - Documentation requirements for audit purposes\n",
      "    \n",
      "\n",
      "---"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:11:49,134 - root - INFO - Completed database query 2/2: internal_capm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## üìä Research Summary\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:11:49,135 - iris.src.agents.agent_summarizer.summarizer - INFO - Generating streaming research summary using model: gpt-4o-2024-08-06\n",
      "2025-04-04 12:11:49,136 - iris.src.agents.agent_summarizer.summarizer - INFO - Summarizing 2 completed queries\n",
      "2025-04-04 12:11:49,150 - iris.src.llm_connectors.rbc_openai - INFO - Using API key: sk-proj...\n",
      "2025-04-04 12:11:49,151 - iris.src.llm_connectors.rbc_openai - INFO - Using API base URL: https://api.openai.com/v1\n",
      "2025-04-04 12:11:49,151 - iris.src.llm_connectors.rbc_openai - INFO - Making streaming call to model: gpt-4o-2024-08-06 in local environment\n",
      "2025-04-04 12:11:49,152 - iris.src.llm_connectors.rbc_openai - INFO - Attempt 1/3: Sending request to OpenAI API\n",
      "2025-04-04 12:11:49,152 - iris.src.llm_connectors.rbc_openai - INFO - API call parameters (excluding message content): {'model': 'gpt-4o-2024-08-06', 'max_tokens': 4096, 'temperature': 0.1, 'stream': True, 'timeout': 30, 'stream_options': {'include_usage': True}}\n",
      "2025-04-04 12:11:49,745 - httpx - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2025-04-04 12:11:49,746 - iris.src.llm_connectors.rbc_openai - INFO - Received response in 0.59 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Key Findings\n",
      "\n",
      "The research aimed to define a business combination under IFRS and explore the relevant accounting treatment, particularly within the RBC context. The search was conducted across internal databases, focusing on the internal wiki and Corporate Accounting Policy Manuals (CAPM).\n",
      "\n",
      "### Definition and Guidance\n",
      "\n",
      "1. **Internal Wiki (Query 1):** Unfortunately, the search in the internal wiki did not yield specific results regarding the definition of a business combination under IFRS or any RBC-specific guidance. This indicates a potential gap in the internal wiki's coverage of this topic.\n",
      "\n",
      "2. **Corporate Accounting Policy Manuals (Query 2):** The CAPM search provided some related policy guidelines, although not directly addressing business combinations:\n",
      "   - **Policy Section PR-23.4:** Focuses on accounting for financial instruments, including classification, measurement, and recognition criteria. While relevant to financial reporting, it does not specifically address business combinations.\n",
      "   - **Policy Section PR-14.7:** Covers revenue recognition standards, detailing the five-step model and performance obligations. Again, this is tangentially related but not directly applicable to business combinations.\n",
      "   - **Procedural Guidance PG-112:** Offers implementation examples and decision trees for complex financial instruments, which might be useful for understanding broader financial reporting contexts but not specifically for business combinations.\n",
      "\n",
      "### Analysis and Considerations\n",
      "\n",
      "- **Lack of Direct Results:** The absence of direct information on business combinations in both the internal wiki and CAPM suggests that RBC may not have a centralized or explicit internal resource specifically addressing this IFRS topic. This could necessitate consulting external IFRS guidance or internal accounting specialists for detailed insights.\n",
      "\n",
      "- **Potential Next Steps:** Given the lack of specific internal guidance, it would be prudent to consult external sources such as the IASB standards or external firm guidance (EY, KPMG, PwC) for comprehensive IFRS definitions and treatments of business combinations. Additionally, reaching out to the Accounting Policy Group within RBC could provide tailored insights and ensure compliance with internal practices.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "The research highlighted a gap in the internal documentation regarding the definition and accounting treatment of business combinations under IFRS within RBC. While related policy sections were identified, they do not directly address the query. For precise guidance, it is recommended to consult external IFRS resources and engage with RBC's Accounting Policy Group. This approach will ensure that any accounting treatments align with both international standards and RBC's internal policies.\n",
      "\n",
      "This summary underscores the importance of verifying information with accounting specialists and considering external authoritative sources when internal documentation is insufficient."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:11:59,490 - iris.src.llm_connectors.rbc_openai - INFO - Token usage - Completion: 507 ($0.0000), Prompt: 2392 ($0.0000), Total: 2899 tokens, Total Cost: $0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "Completed 2 database queries.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-04 12:11:59,494 - root - INFO - Completed research process\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "---\n",
      "## Usage Statistics\n",
      "\n",
      "- Input tokens: 2392\n",
      "- Output tokens: 507\n",
      "- Total tokens: 2899\n",
      "- Cost: $0.000039\n",
      "- Time: 18.17 seconds\n",
      "\n",
      "### Database Token Usage\n",
      "\n",
      "**APG Wiki Entries**\n",
      "- Input tokens: 371\n",
      "- Output tokens: 2\n",
      "- Total tokens: 373\n",
      "- Cost: $0.000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Call the model function with our conversation and debug mode enabled\n",
    "result_generator = model(conversation, debug_mode=True)\n",
    "\n",
    "# Collect all response chunks and debug data\n",
    "response_chunks = []\n",
    "debug_data = None\n",
    "\n",
    "for chunk in result_generator:\n",
    "    # Check if this is debug data or a regular response chunk\n",
    "    if chunk.startswith(\"\\n\\nDEBUG_DATA:\"):\n",
    "        debug_data_json = chunk.replace(\"\\n\\nDEBUG_DATA:\", \"\")\n",
    "        import json\n",
    "        debug_data = json.loads(debug_data_json)\n",
    "    else:\n",
    "        response_chunks.append(chunk)\n",
    "        print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": "# Set up a widescreen dashboard visualization for process analytics and token usage\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.ticker as ticker\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.patches as patches\n\n# RBC color theme\nrbc_colors = {\n    'primary_blue': '#0051A5',  # RBC Royal Blue\n    'secondary_blue': '#0073AE', # RBC Secondary Blue\n    'accent_blue': '#00A7E1',   # RBC Light Blue\n    'dark_blue': '#003168',     # RBC Dark Blue\n    'gold': '#F4C63D',          # RBC Gold\n    'navy': '#14133B',          # RBC Navy\n    'red': '#C40022',           # RBC Red\n    'light_gray': '#EAEAEA',    # Light Gray for backgrounds\n    'medium_gray': '#D0D0D0'    # Medium Gray for tile backgrounds\n}\n\n# Set the matplotlib style\nplt.style.use('seaborn-v0_8-whitegrid')\n\nif debug_data:\n    # Sort the decisions by timestamp to ensure correct ordering\n    decisions_sorted = sorted(debug_data['decisions'], key=lambda x: datetime.fromisoformat(x['timestamp']))\n    \n    # Define stage order and display names\n    stage_order = [\n        'router',       # 1. Initial routing decision\n        'clarifier',    # 2. Clarify research needs\n        'planner',      # 3. Create query plan\n        'database_query', # 4. Execute database queries\n        'judge',        # 5. Evaluate research progress\n        'summary'       # 6. Generate final summary\n    ]\n    \n    # Better display names for stages\n    stage_display_names = {\n        'router': '1. Router',\n        'clarifier': '2. Clarifier',\n        'planner': '3. Planner',\n        'database_query': '4. Database Query',\n        'judge': '5. Judge',\n        'summary': '6. Summary'\n    }\n    \n    # Create dataframe from stage data\n    stages_data = []\n    for decision in decisions_sorted:\n        stage = decision['stage']\n        timestamp = datetime.fromisoformat(decision['timestamp'])\n        if 'token_usage' in decision:\n            token_usage = decision['token_usage']\n            stages_data.append({\n                'stage': stage,\n                'display_name': stage_display_names.get(stage, stage),\n                'timestamp': timestamp,\n                'prompt_tokens': token_usage['prompt'],\n                'completion_tokens': token_usage['completion'],\n                'total_tokens': token_usage['total'],\n                'cost': token_usage['cost']\n            })\n    \n    # Create dataframe\n    df_stages = pd.DataFrame(stages_data)\n    \n    # Calculate relative time from start\n    start_time = datetime.fromisoformat(debug_data['start_timestamp'])\n    df_stages['time_seconds'] = (df_stages['timestamp'] - start_time).dt.total_seconds()\n    \n    # Group by stage and sum tokens\n    stage_totals = df_stages.groupby(['stage', 'display_name']).agg({\n        'prompt_tokens': 'sum',\n        'completion_tokens': 'sum',\n        'total_tokens': 'sum',\n        'cost': 'sum'\n    }).reset_index()\n    \n    # Sort by stage order\n    stage_totals['stage_order'] = stage_totals['stage'].map({s: i for i, s in enumerate(stage_order)})\n    stage_totals = stage_totals.sort_values('stage_order')\n    \n    # Prepare timeline data\n    timeline_data = []\n    for i, decision in enumerate(decisions_sorted):\n        stage = decision['stage']\n        start_time = datetime.fromisoformat(decision['timestamp'])\n        # End time is either the next decision's timestamp or the end timestamp\n        if i + 1 < len(decisions_sorted):\n            end_time = datetime.fromisoformat(decisions_sorted[i+1]['timestamp'])\n        else:\n            end_time = datetime.fromisoformat(debug_data['end_timestamp'])\n        \n        # Add to timeline data\n        timeline_data.append({\n            'stage': stage,\n            'display_name': stage_display_names.get(stage, stage),\n            'start_time': start_time,\n            'end_time': end_time,\n            'duration': (end_time - start_time).total_seconds()\n        })\n    \n    # Create timeline dataframe\n    df_timeline = pd.DataFrame(timeline_data)\n    \n    # Calculate relative times from overall start\n    overall_start = datetime.fromisoformat(debug_data['start_timestamp'])\n    df_timeline['start_seconds'] = (df_timeline['start_time'] - overall_start).dt.total_seconds()\n    df_timeline['end_seconds'] = (df_timeline['end_time'] - overall_start).dt.total_seconds()\n    \n    # Sort by chronological order (start time)\n    df_timeline = df_timeline.sort_values('start_seconds')\n    \n    # Filter out duplicate entries - keep only the earliest occurrence of each stage\n    df_timeline = df_timeline.drop_duplicates(subset=['stage'], keep='first')\n    \n    # Prepare database data if available\n    db_data = []\n    if debug_data['tokens']['databases']:\n        for db_name, usage in debug_data['tokens']['databases'].items():\n            # Make display name more readable\n            display_name = db_name.replace('internal_', '').replace('external_', '').upper()\n            db_data.append({\n                'database': db_name,\n                'display_name': display_name,\n                'prompt_tokens': usage['prompt_tokens'],\n                'completion_tokens': usage['completion_tokens'],\n                'total_tokens': usage['total_tokens'],\n                'cost': usage['cost']\n            })\n        \n        # Create dataframe\n        df_db = pd.DataFrame(db_data)\n    \n    # Calculate overall stats\n    total_duration = (datetime.fromisoformat(debug_data['end_timestamp']) - \n                     datetime.fromisoformat(debug_data['start_timestamp'])).total_seconds()\n    \n    # Define colors for different stages\n    stage_colors = {\n        'router': rbc_colors['primary_blue'],\n        'clarifier': rbc_colors['secondary_blue'],\n        'planner': rbc_colors['accent_blue'],\n        'database_query': rbc_colors['navy'],\n        'judge': rbc_colors['gold'],\n        'summary': rbc_colors['red']\n    }\n    \n    # Create a clean dashboard layout\n    fig = plt.figure(figsize=(20, 16))\n    \n    # Create top stats tiles - fixed layout\n    # 1. Create a row of 5 tiles at the top - one for each stat and cost\n    stat_tiles = [\n        {\"title\": \"Total Time\", \"value\": f\"{total_duration:.2f} sec\", \"color\": rbc_colors['primary_blue']},\n        {\"title\": \"Total Tokens\", \"value\": f\"{debug_data['tokens']['total']:,}\", \"color\": rbc_colors['secondary_blue']},\n        {\"title\": \"Prompt Tokens\", \"value\": f\"{debug_data['tokens']['prompt']:,}\", \"color\": rbc_colors['accent_blue']},\n        {\"title\": \"Completion Tokens\", \"value\": f\"{debug_data['tokens']['completion']:,}\", \"color\": rbc_colors['gold']},\n        {\"title\": \"Total Cost\", \"value\": f\"${debug_data['cost']:.6f}\", \"color\": rbc_colors['red']}\n    ]\n    \n    # Create a simple 3-row grid layout (stats row, token charts row, timeline row)\n    # Create stats row - manually positioned rectangles \n    for i, stat in enumerate(stat_tiles):\n        # Calculate position for each tile\n        left = 0.05 + (i * 0.19)  # 5 tiles across the full width with small gaps\n        bottom = 0.85\n        width = 0.17\n        height = 0.10\n        \n        # Create a rectangle for the tile\n        rect = patches.Rectangle((left, bottom), width, height, \n                                linewidth=2, edgecolor=stat[\"color\"],\n                                facecolor=rbc_colors['medium_gray'], alpha=0.3)\n        fig.add_artist(rect)\n        \n        # Add text directly to the figure\n        fig.text(left + width/2, bottom + height*0.65, stat[\"title\"], \n                ha='center', va='center', fontsize=14, fontweight='bold', \n                color=rbc_colors['dark_blue'])\n        \n        fig.text(left + width/2, bottom + height*0.35, stat[\"value\"], \n                ha='center', va='center', fontsize=16, fontweight='bold',\n                color=stat[\"color\"])\n    \n    # Token Usage Charts Row - create two axes side by side\n    ax_tokens = fig.add_axes([0.05, 0.5, 0.42, 0.3])  # [left, bottom, width, height]\n    ax_db = fig.add_axes([0.53, 0.5, 0.42, 0.3])\n    \n    # Timeline row - larger chart at bottom\n    ax_timeline = fig.add_axes([0.05, 0.08, 0.9, 0.35])\n    \n    # Add title at the top\n    fig.text(0.5, 0.96, 'IRIS System Performance Dashboard', \n            ha='center', va='center', fontsize=24, fontweight='bold',\n            color=rbc_colors['dark_blue'])\n    \n    # 1. Create the Token Usage by Stage chart\n    bar_width = 0.35\n    x = np.arange(len(stage_totals))\n    \n    # Plot bar chart with larger bars\n    prompt_bars = ax_tokens.bar(x - bar_width/2, stage_totals['prompt_tokens'], bar_width, \n                         label='Prompt tokens', color=rbc_colors['primary_blue'])\n    completion_bars = ax_tokens.bar(x + bar_width/2, stage_totals['completion_tokens'], bar_width, \n                             label='Completion tokens', color=rbc_colors['gold'])\n    \n    # Add value labels on top of bars\n    for bars in [prompt_bars, completion_bars]:\n        for bar in bars:\n            height = bar.get_height()\n            ax_tokens.text(bar.get_x() + bar.get_width()/2., height + 50,\n                    f'{height:,}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n    \n    ax_tokens.set_xlabel('Processing Stage', fontsize=14, fontweight='bold')\n    ax_tokens.set_ylabel('Number of Tokens', fontsize=14, fontweight='bold')\n    ax_tokens.set_title('Token Usage by Processing Stage', fontsize=18, fontweight='bold', color=rbc_colors['dark_blue'])\n    ax_tokens.set_xticks(x)\n    ax_tokens.set_xticklabels(stage_totals['display_name'], rotation=45, ha='right', fontsize=12)\n    ax_tokens.tick_params(axis='y', labelsize=12)\n    \n    # Format y-axis with comma for thousands\n    ax_tokens.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n    \n    # Add legend with better position\n    ax_tokens.legend(loc='upper right', frameon=True, framealpha=0.9, fontsize=12)\n    \n    # Set background color\n    ax_tokens.set_facecolor(rbc_colors['light_gray'])\n    \n    # Add extra space at top for labels\n    y_top = max([max(stage_totals['prompt_tokens']), max(stage_totals['completion_tokens'])]) * 1.15\n    ax_tokens.set_ylim(0, y_top)\n    \n    # 2. Create the Database Usage chart\n    if len(db_data) > 0:\n        # Create a grouped bar chart\n        x = np.arange(len(df_db))\n        \n        # Plot bar chart with larger bars\n        prompt_bars = ax_db.bar(x - bar_width/2, df_db['prompt_tokens'], bar_width, \n                             label='Prompt tokens', color=rbc_colors['primary_blue'])\n        completion_bars = ax_db.bar(x + bar_width/2, df_db['completion_tokens'], bar_width, \n                                 label='Completion tokens', color=rbc_colors['gold'])\n        \n        # Add value labels on top of bars\n        for bars in [prompt_bars, completion_bars]:\n            for bar in bars:\n                height = bar.get_height()\n                ax_db.text(bar.get_x() + bar.get_width()/2., height + 5,\n                        f'{height:,}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n        \n        ax_db.set_xlabel('Database', fontsize=14, fontweight='bold')\n        ax_db.set_ylabel('Number of Tokens', fontsize=14, fontweight='bold')\n        ax_db.set_title('Token Usage by Database', fontsize=18, fontweight='bold', color=rbc_colors['dark_blue'])\n        ax_db.set_xticks(x)\n        ax_db.set_xticklabels(df_db['display_name'], rotation=45, ha='right', fontsize=12)\n        ax_db.tick_params(axis='y', labelsize=12)\n        \n        # Format y-axis with comma for thousands\n        ax_db.yaxis.set_major_formatter(ticker.StrMethodFormatter('{x:,.0f}'))\n        \n        # Add legend in a non-overlapping position\n        ax_db.legend(loc='upper right', frameon=True, framealpha=0.9, fontsize=12)\n        \n        # Set background color\n        ax_db.set_facecolor(rbc_colors['light_gray'])\n        \n        # Add extra space at top for labels\n        y_top = max([max(df_db['prompt_tokens']), max(df_db['completion_tokens'])]) * 1.15\n        ax_db.set_ylim(0, y_top)\n    \n    # 3. Create the Timeline Visualization \n    # Increase spacing between bars - MUCH larger height for visibility\n    height = 0.8\n    spacing = 1.5\n    \n    # Plot horizontal bars for each stage - reversed to show first stage at top\n    for i, row in df_timeline.iloc[::-1].reset_index(drop=True).iterrows():\n        stage = row['stage']\n        duration = row['duration']\n        duration_width = row['end_seconds'] - row['start_seconds']\n        color = stage_colors.get(stage, 'gray')\n        \n        position = i * spacing\n        \n        # Create the bar - much taller\n        ax_timeline.barh(position, duration_width, left=row['start_seconds'], height=height, color=color)\n        \n        # Add text label - with different positioning based on bar width\n        if duration_width > 1.5:  # For bars wide enough to contain text\n            # Position text inside the bar with white color\n            text_pos = row['start_seconds'] + duration_width/2\n            label = f\"{row['display_name']} ({duration:.2f}s)\"\n            ax_timeline.text(text_pos, position, label, ha='center', va='center',\n                    color='white', fontweight='bold', fontsize=14,\n                    bbox=dict(boxstyle=\"round,pad=0.3\", fc=color, ec=\"none\", alpha=0.9))\n        else:  # For narrow bars, position text outside\n            label = f\"{row['display_name']} ({duration:.2f}s)\"\n            text_pos = row['end_seconds'] + 0.5\n            ax_timeline.text(text_pos, position, label, ha='left', va='center',\n                    color='black', fontweight='bold', fontsize=14)\n    \n    # Adjust y-ticks and labels - add stage names on the left\n    positions = [i * spacing for i in range(len(df_timeline))]\n    reversed_names = df_timeline.iloc[::-1]['display_name'].tolist()\n    ax_timeline.set_yticks(positions)\n    ax_timeline.set_yticklabels(reversed_names, fontsize=12)\n    \n    ax_timeline.set_xlabel('Time (seconds)', fontsize=14, fontweight='bold')\n    ax_timeline.set_title('Timeline of Processing Stages', fontsize=18, fontweight='bold', color=rbc_colors['dark_blue'])\n    ax_timeline.tick_params(axis='x', labelsize=12)\n    \n    # Add gridlines and format x-axis with decimal places\n    ax_timeline.grid(axis='x', linestyle='--', alpha=0.7)\n    ax_timeline.xaxis.set_major_formatter(ticker.StrMethodFormatter('{x:.2f}s'))\n    \n    # Set background color\n    ax_timeline.set_facecolor(rbc_colors['light_gray'])\n    \n    # Set y-limits with more space\n    ax_timeline.set_ylim(-1, max(positions) + 1)\n    \n    # Add legend for timeline stages \n    handles = [patches.Patch(color=color, label=stage_display_names.get(stage, stage)) \n              for stage, color in stage_colors.items()]\n    ax_timeline.legend(handles=handles, loc='upper right', fontsize=12, frameon=True, framealpha=0.7)\n    \n    # Adjust figure layout\n    plt.show()\nelse:\n    print(\"No debug data available. Make sure to run with debug_mode=True.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}