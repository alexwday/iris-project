{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables auto-reloading of modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import the model\n",
    "from iris.src.chat_model.model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversation for testing\n",
    "conversation = {\n",
    "    \"messages\": [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant specialized in accounting.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Can you find any documents in the internal wiki that are relevant to tax accounting? I need information specifically about how to handle deferred taxes under IFRS.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Before proceeding with research, please clarify:\\n\\n1. Are you looking for specific aspects of deferred taxes, such as recognition, measurement, or disclosure requirements?\\n2. Are you interested in any particular industry-specific considerations for deferred taxes?\\n3. Do you need information about recent changes to IFRS standards related to tax accounting?\"},\n",
    "        {\"role\": \"user\", \"content\": \"Just from internal wiki, I'm specifically looking for how to measure deferred tax assets and liabilities according to IAS 12. I need practical examples of temporary differences and how to calculate the tax base. I'm working in the financial services industry, so examples in that context would be most helpful.\"}\n",
    "    ]\n",
    "}\n",
    "\n",
    "# You can modify the conversation above to test different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the model function with our conversation and capture full response without streaming\n",
    "result = \"\".join(model(conversation, debug_mode=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and analyze the model response and debug data\n",
    "import json\n",
    "\n",
    "# Extract model response and debug data\n",
    "response_content = result\n",
    "debug_data = None\n",
    "\n",
    "if \"\\n\\nDEBUG_DATA:\" in result:\n",
    "    # Split the response to separate content from debug data\n",
    "    parts = result.split(\"\\n\\nDEBUG_DATA:\")\n",
    "    response_content = parts[0]\n",
    "    debug_json = parts[1]\n",
    "    debug_data = json.loads(debug_json)\n",
    "\n",
    "# Print the complete debug process with integrated model response\n",
    "print(\"# IRIS MODEL DEBUG OUTPUT\\n\")\n",
    "\n",
    "# Function to print a section header\n",
    "def print_section(title):\n",
    "    print(f\"\\n{'='*80}\\n{title}\\n{'='*80}\\n\")\n",
    "\n",
    "# Initialize variables to track process flow\n",
    "current_step = \"initialization\"\n",
    "has_printed_response = False\n",
    "\n",
    "# Process each decision in sequence\n",
    "if debug_data and \"decisions\" in debug_data:\n",
    "    # INITIALIZATION\n",
    "    print_section(\"INITIALIZATION\")\n",
    "    print(\"Starting model process...\\n\")\n",
    "    \n",
    "    # ROUTING DECISION\n",
    "    router_decisions = [d for d in debug_data[\"decisions\"] if d[\"stage\"] == \"router\"]\n",
    "    if router_decisions:\n",
    "        print_section(\"ROUTING DECISION\")\n",
    "        decision = router_decisions[0][\"decision\"]\n",
    "        print(f\"Model decided to use: {decision['function_name']}\\n\")\n",
    "    \n",
    "    # CLARIFICATION\n",
    "    clarifier_decisions = [d for d in debug_data[\"decisions\"] if d[\"stage\"] == \"clarifier\"]\n",
    "    if clarifier_decisions:\n",
    "        print_section(\"CLARIFICATION\")\n",
    "        decision = clarifier_decisions[0][\"decision\"]\n",
    "        print(f\"Research Statement: {decision['output']}\\n\")\n",
    "        print(f\"Is continuation: {decision['is_continuation']}\\n\")\n",
    "    \n",
    "    # PLANNING\n",
    "    planner_decisions = [d for d in debug_data[\"decisions\"] if d[\"stage\"] == \"planner\"]\n",
    "    if planner_decisions:\n",
    "        print_section(\"RESEARCH PLANNING\")\n",
    "        queries = planner_decisions[0][\"decision\"][\"queries\"]\n",
    "        print(f\"Created research plan with {len(queries)} queries:\\n\")\n",
    "        for i, query in enumerate(queries):\n",
    "            print(f\"{i+1}. Database: {query['database']}\")\n",
    "            print(f\"   Query: {query['query']}\\n\")\n",
    "    \n",
    "    # DATABASE QUERIES\n",
    "    db_decisions = [d for d in debug_data[\"decisions\"] if d[\"stage\"] == \"database_query\"]\n",
    "    for i, decision in enumerate(db_decisions):\n",
    "        print_section(f\"QUERY {i+1}: {decision['decision']['database'].upper()}\")\n",
    "        db_data = decision[\"decision\"]\n",
    "        print(f\"Query: {db_data['query']}\\n\")\n",
    "        \n",
    "        # Extract the results from the query\n",
    "        if i < len(planner_decisions[0][\"decision\"][\"queries\"]):\n",
    "            results = planner_decisions[0][\"decision\"][\"queries\"][i][\"results\"]\n",
    "            print(\"Results:\")\n",
    "            print(results)\n",
    "        \n",
    "        # Show judgment after first query\n",
    "        if i == 0:\n",
    "            judge_decisions = [d for d in debug_data[\"decisions\"] if d[\"stage\"] == \"judge\"]\n",
    "            if judge_decisions:\n",
    "                print_section(\"RESEARCH JUDGMENT\")\n",
    "                decision = judge_decisions[0][\"decision\"]\n",
    "                print(f\"Action: {decision['action']}\\n\")\n",
    "                print(f\"Reason: {decision.get('reason', 'No reason provided')}\\n\")\n",
    "    \n",
    "    # MODEL RESPONSE\n",
    "    print_section(\"FINAL MODEL RESPONSE\")\n",
    "    print(response_content)\n",
    "    \n",
    "    # PROCESS COMPLETION\n",
    "    print_section(\"PROCESS COMPLETE\")\n",
    "    print(f\"Completed at: {debug_data['end_timestamp']}\")\n",
    "    print(f\"Total decisions: {len(debug_data['decisions'])}\")\n",
    "else:\n",
    "    print(\"No debug data available in the response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Display token and cost information\n",
    "if debug_data:\n",
    "    from datetime import datetime\n",
    "    \n",
    "    # Display token usage and cost information if available\n",
    "    if \"tokens\" in debug_data:\n",
    "        print(\"Token Usage and Cost Information:\")\n",
    "        print(\"---------------------------------\")\n",
    "        print(f\"Total tokens: {debug_data['tokens']['total']}\")\n",
    "        print(f\"  - Prompt tokens: {debug_data['tokens']['prompt']}\")\n",
    "        print(f\"  - Completion tokens: {debug_data['tokens']['completion']}\")\n",
    "        \n",
    "        # Add database token information if available\n",
    "        if \"databases\" in debug_data[\"tokens\"] and debug_data[\"tokens\"][\"databases\"]:\n",
    "            db_tokens = 0\n",
    "            db_cost = 0\n",
    "            for db, usage in debug_data[\"tokens\"][\"databases\"].items():\n",
    "                db_tokens += usage[\"total_tokens\"]\n",
    "                db_cost += usage[\"cost\"]\n",
    "            print(f\"  - Database tokens: {db_tokens}\")\n",
    "            print(f\"  - Database cost: ${db_cost:.6f}\")\n",
    "        \n",
    "        # Format cost with fixed decimal notation to avoid scientific notation for small values\n",
    "        print(f\"Total cost: ${debug_data['cost']:.6f}\")\n",
    "        \n",
    "        # Calculate time taken\n",
    "        if \"start_timestamp\" in debug_data and \"end_timestamp\" in debug_data:\n",
    "            start_time = datetime.fromisoformat(debug_data[\"start_timestamp\"])\n",
    "            end_time = datetime.fromisoformat(debug_data[\"end_timestamp\"])\n",
    "            duration = (end_time - start_time).total_seconds()\n",
    "            print(f\"Total processing time: {duration:.2f} seconds\")\n",
    "        print()\n",
    "    \n",
    "    print(\"Raw debug data structure:\")\n",
    "    print(json.dumps(debug_data, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an enhanced agent decision workflow timeline visualization\n",
    "if debug_data and \"decisions\" in debug_data:\n",
    "    from datetime import datetime\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "                                \n",
    "    # Exttafttfmfrtifrm
    "    decisions = \]nnn
    g
       ss]
    "    d[sgpipis[]
      
    "    # Extpa txodniini  r][aalc]f r]each ttage        n",
    "    ##Exctcion r ea r each ste     
    "# Ex# Exccnrh   in  ,]ah g    
    "    ##Excs der.appead(stgec)ser.appead(stge\)n
    "    fonediigi.epge)
    "        stagad.append(s(sta)ssages.append(stage)ge)ssages.append(stage)\n",
    "        ddExE\a"s"g"tm]s,farmg\d#"msis,nndmiy\nsofo ty\rtd sypn# gs typendmiypnsofo ty\rti sypntage type\n",
    "        if stage == \"router\":\n",
    "            descoetnction_name', 'Unknown')}\"\n",
    "        elif stage == \"clarifier\":\n",
    "            descieion.get('decision', {}).get('is_continuation', False) else \"New Research\")\n",
    "        elif stage == \"planner\":\n",
    "            query_count = len(decision.get('decision', {}).get('queries', []))\n",
    "            desc
    "        elif stage == \"database_query\":st"ame}"\
    "        lf ud:{
    "   deio =g
    i=g
    "    ##C
    "    mc
    "    ##Cgml F
Cgml"fFg
  "D:C
    "mle
 ,CgmDaFn
    "timeftmoiiepafd.D5iFis(
"g'f_'Dsloc[-1]=l':t   \-"tmldf'o[-1]ol_f #Oe
    "f })n'e'
    "''nt-1bu =e\:fotmaneot''oc[ if available]).otl_f  # Orange\n",
    "m)i)orisvt
n'le"\k(f=a"\._s('Tst')
    "ion Soytimesamforaoa talen_n"r_ag[tag] =dbg_a["s\"]stags][stage[tot]
    "#sC_tumsnsado='lstmfpev(us:T
    "stagw'Stage']n,
l_CDlua[ wur in'.iff()shft(-1).t.tol_
    "am  rw['p['i i']h=e i\   sterft'ici_.dff().hta(-1)..gg_b.uaga[apho=0.8,][\".oc1:stages\"][stage][\"total\"]\n",
    "heIf th0.l"s,mrwsummrystgohosdrao dstimat io=ulretf_ev(us:T
    "ge'Ht'l]heda\,=mfhrv
_Tim"u#=Dstgi .g.0.yf():ila.5f)\yhed_[ta(f.oi istagDun.-1])   r  ativ   rEs]dto'ivdnt()1n    heIf th0.l"sha='wmryer', draon,stimat i
    'f 'Hfirst_tsilthenff w]uaary"r[fso\oooiy=peha=3im
    " # Dtext(t,s-0.5,ff\"{t:.1f}s\", h5='c\ytar', va='top', forfsize=8, aipha=0.8istagDuno.-1]):   r  ativ    Esidso ov nt enn                ha='center', \n",
    '    #fGeirafottyp lnnff Tw]us"aatmery"r[tfso\omp oo es ir ty=pleha=3im
    "-0Ads5,gfl{se1s,lie_f[Dttao'].[-1]SWototpa-"timmisdfcdoc[-1]).otl_)2)n
    "l_.bfr[rw['l
.o-d[    lt.bargrw[Def,0.5cods'lclnd or=  l,stydi),bfonno ifvilble
gend[_lbelsae    n phns0.8,.oc-1=05
    ,l _cni),ribto fornnotion ifvilble
p o=g"Caugaml0tioisvt
    ")rsagolrs.(
p it",#gAdrl0iftsgins:ioisvt
d a "oaoAdknnpodf[_s]g=l_scds()
    "ummcioSg:ssho\oaCs:${dbug_ata['cos']:.6f}"noaot talAdtekennpcodsinf [_t  s]g=l_seconds()\n",
    ",start_imu+mmtocooh t te,0.98),st: ${debug_data['cost']:.6f}\"\n",
    "sta_0.98),\n",
    " #Go'lfffkoch ,ayo()
    ".sho",
# Go"
' 'l":\fyu\ftno .n(wDul 0.5
}
   "ell_tyCreaephbar"wi"h,basno 
"ot:br=.barh
ot ]s:grw['D.ni]
  },ilt#yCreateptheebar"wi"h,basi infmio 
   "obrPhmnclsfgb"g_
   "sa:an \"[oorkr\ u\w"'l.Dimriby)s,wfin"knionvil
    "me imprt =0.8 atin,
    "imehigh0.6
Peae"Ex,\",
k")
    " an"\t",usggad["kge nkuga"dk"bf()yi[ablp,wfitn"kenionvilbl
    "    me issge
mprt"co0p8toknda[k_pr_g]dbgaaske]s[s]gegag
    "mehigh06)\n",timaossdopor  orr,prssig_",E
xt \'cospe_secdstagekf = dbugabk"s\""sags\"[s"e]\"tlke"edd["tgeenkl\"gk) d:bugi[:
    "    sst.fromot ( =dgdg"ken/dbug\"a",[\"okns\"[3tt)*debug_dat,[cot] f dbu_daa["tok\][  ] > 0 letis0r_seco_d = ,mtao_tstens /rpaocess, g__sec nag ukcsas]agdttimt> 0 else 0    start_time =me.fromiot ( =dgdge_t"kenar/tdsbug\"a",[\"tokns\"[3tta]) * debug_dat,[costtt] if dbu_daa["tokes\][  total\"] > 0 elses0r_second = total_tokens / processing_time if processing_time > 0 else 0\n",
    "_eoecsti_eoecsAds#=dp.orrr  gd[iAads]s==stagr_c.osblyt(r abiplli()t tl  #"Redecdubro mrkrs fr cay
    "ca().ceyim(pl.gca).g_ylim()] -1pli.gce().nctyyeim()[]+c5",
  "n_lPechtemnime)i1e if total_tokens > 0 else 0\n",
    "ut()
cost"ltuotto/citncynmitricsaftow['Dtration']) elslt0.5elins 0 else 0\n",
    "n_efficec=o(comoketion_tok=nsi/ntotol_tokn s)b*a1002if)tonilntokons>0els 0
    "cost_pnrn=tota_cstr/wtotal_to[nf'sotipd.i0n]ftow['Dtsations])" lslt0.uelinst0ke"s] 0ono,+af[_
    "oost_perpl=_ct\", ="tot,l_,ry) /comlo_okns ifcomplio_s > 0 l0
    "\n",Chf6b2)winbaicirmo
    "# Get)dabarticvlbnbr(
figa.lt22i=z,rw['D0\i']e4, 10), dpi=100, facecolor='wh,d"dkise:
    "eslb,:h.,cpo
    "lamtTokeono,+af[_
kes="_ck'C +Tokencol']= \c,,.g(ry)
    "hs0.8
u",p"hedashdnphgh0.6
_sg."(tga)fig,_axest=0plt.subpluo (2, 2, fia.iz=(14, 10),dpi100,fcolr='whie')
    "n_vasuptlues,\n",
itIS"mProat alAddtdkkea coivibl
    ")\n",s1.tC_igiisk .pmeirg2:
    "kenen_mtTokekaesok_prsgsg,]', 'Comle Tken']
    "su",e_sg.(tga_t0)ut textsumm x1.piop",
    "token_values,autopct='%1.1f%%',n'ce\ter',
    "star)\n",ste=t_im0+\duaio/2
    "labes=t3ken_label', '#83c1f7'],\n",
    "   w#ePlacedsummarygineiop-wt0g ccroer='white'),\n",
    "autopci='%1.1f%%',1'c1\tero,
    "stweiangl:=90bold'},\n",
    "0.75\sn"'#f73883'#83c1f7],\n",
"   wedgeps=dic(wdth=0.6, gecolor=whi)
    "    )\n"s={'fontsize':11,'fontweight':'bod'}
    "    \n",nc7593black
    "    textelements\n",
    "    .max()for autotext in autotexts:\n",
    "# Adthed exdxrtementobutter abeeit_\nn'tlbdRecednmberfmakrs for clariy
   "p    l.mx()fr utextuoxs:
    "#pAddlmoretpadding.totYiaxisgt_lt(tbutter\abeent_\"n'bdRcenmbfmak\fornclariy
","pl.gca().e_yim(pl.gc().t_ylim()[0]-1,p.c().gt_ylim()[1 + 0.5)
    "\n",
d do"plw.hugh_lyou()
\n","
    "da,uthle ith smmry
    "ax1.text(\n",
    "0, 00,,0,,
    "        f\"Totnl\\n{_oeal_tns:,n:,}\\nTek,nn",\
    "        ha='cten'
     fonts1,fnniz=14
    "weigfontweighld'hld'\n",
    o so,[]
n",tec.am)x
.   "  e",tage c los(nagt_tite('ToknDtribuionfnz=14,pa=20)
.   "       tieg'.ke i()buts, pad=20)\n",
    "ekeysKayMDply(TopRighl-yU i)-ppskattablx-lykenxtdiply
    "       aax2x=2axes[0, 1]= axes[0, 1]\n",
    " witah wtthtaesaimandoks
    " toesadvaabbse l\kens"avlbe
    "cs =m[cs=[
    "otalPimeotssPimeroTissimg Tim\ \" e\"{pdoce,ting_mimr:.2f}_secend:\"],}\"],\n",
    "\n",okenspe Secd\",f\"{oes_pso:.2}\"],\",
    "     
    "    [\"Cost per Second\", f\"${cost_per_second:.8f}\"],\n",
    "    [\"Token Efficiency\", f\"{token_efficiency:.1f}%\"],\n",
    "    [\"Cost per Token\", f\"${cos\n",
    "t_per_token:.8f}\"],\n",
    "        )    [\"Cost per Output Token\", f\"${cost_per_output_token:.8f}\"],\n",
    "    [\"Dtabase Tokens\", f\"{db_token_count:,}\"],\n",
    "        # Place summary in top-left corner\n",
    "    [\"Database Cost\", f\"${db_cost:.8f}\"],\n",
    "    [\"Total Cost\", f\"${total_cost:.6f}\"]\n",
    "]\n",
    "\n",
    "# Hide axes\n",
    "ax2.axis('off')\n",
    "    \n",
    "    # Createle-like display\n",
    "    cellt = [[m[0], m[1]] for m in metrics]\n",
    "        table = ax2.table(\n",\n",
    "    # Add more padding to Y axis for better readability
    "\n",ca().seyim(pl.gca).g_ylim()] -1plt.gca().get_ylim()[]+ 5\n",
  "        cellText=cell_text,\n",
    " l.gh_yout()
    "    colLabels=[\"Metric\", \"Value\"],\n",
    "    loc='center',\n",
    "        cellLoc='left',\n",
    "        colWidths=[0.5, 0.5]\n",
    "    )\n",
    "    \n",
    "    # Style the table\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 1.8)\n",
    "    \n",
    "    # Style header row\n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        if row == 0:  # Header row\n",
    "            cell.set_text_props(fontweight='bold')\n",
    "            cell.set_facecolor('#e0e0e0')\n",
    "        else:\n",
    "            if col == 1:  # Value column\n",
    "                cell.set_text_props(fontweight='bold')\n",
    "    \n",
    "    ax2.set_title('Key Performance Metrics', fontsize=14, pad=20)\n",
    "    \n",
    "    # 3. Cost Efficiency Gauge (Bottom Left)\n",
    "    ax3 = axes[1, 0]\n",
    "    \n",
    "    # Create a gauge-like visualization for cost efficiency\n",
    "    # We'll use token efficiency as a proxy for cost efficiency\n",
    "    gauge_value = token_efficiency / 100  # Convert to 0-1 scale\n",
    "    \n",
    "    # Draw gauge background\n",
    "    theta = np.linspace(-np.pi/2, np.pi/2, 100)\n",
    "    r = 0.8\n",
    "    x = r * np.cos(theta)\n",
    "    y = r * np.sin(theta)\n",
    "    \n",
    "    # Create gradient colors for gauge\n",
    "    cmap = plt.cm.RdYlGn  # Red to Yellow to Green colormap\n",
    "    colors = cmap(np.linspace(0, 1, 100))\n",
    "    \n",
    "    # Draw gauge segments\n",
    "    for i in range(99):\n",
    "        ax3.fill_between(\n",
    "            [x[i], x[i+1]], [y[i], y[i+1]], [0, 0],\n",
    "            color=colors[i],\n",
    "            alpha=0.8,\n",
    "            edgecolor='none'\n",
    "        )\n",
    "    \n",
    "    # Draw gauge outline\n",
    "    ax3.plot(x, y, 'k', linewidth=2)\n",
    "    \n",
    "    # Draw gauge needle\n",
    "    needle_theta = -np.pi/2 + np.pi * gauge_value\n",
    "    needle_x = [0, r * 0.9 * np.cos(needle_theta)]\n",
    "    needle_y = [0, r * 0.9 * np.sin(needle_theta)]\n",
    "    ax3.plot(needle_x, needle_y, 'k-', linewidth=3)\n",
    "    ax3.plot([0], [0], 'ko', markersize=10)\n",
    "    \n",
    "    # Add tick marks and labels\n",
    "    tick_positions = np.linspace(-np.pi/2, np.pi/2, 5)\n",
    "    tick_labels = [\"0%\", \"25%\", \"50%\", \"75%\", \"100%\"]\n",
    "    \n",
    "    for pos, label in zip(tick_positions, tick_labels):\n",
    "        tick_x = r * 1.1 * np.cos(pos)\n",
    "        tick_y = r * 1.1 * np.sin(pos)\n",
    "        ax3.text(\n",
    "            tick_x, tick_y, label,\n",
    "            ha='center' if pos == np.pi/2 else ('left' if pos > 0 else 'right'),\n",
    "            va='center',\n",
    "            fontsize=10,\n",
    "            fontweight='bold'\n",
    "        )\n",
    "    \n",
    "    # Add value in the center\n",
    "    ax3.text(\n",
    "        0, -0.2,\n",
    "        f\"{token_efficiency:.1f}%\",\n",
    "        ha='center',\n",
    "        va='center',\n",
    "        fontsize=16,\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    \n",
    "    ax3.set_xlim(-1.2, 1.2)\n",
    "    ax3.set_ylim(-0.5, 1.2)\n",
    "    ax3.axis('equal')\n",
    "    ax3.axis('off')\n",
    "    ax3.set_title('Token Efficiency', fontsize=14, pad=20)\n",
    "    \n",
    "    # 4. Token Breakdown Visualization (Bottom Right)\n",
    "    ax4 = axes[1, 1]\n",
    "    \n",
    "    # Check if we have stage-specific data\n",
    "    has_stage_data = \"stages\" in debug_data[\"tokens\"]\n",
    "    \n",
    "    if has_stage_data:\n",
    "        # Extract stage data\n",
    "        stages = list(debug_data[\"tokens\"][\"stages\"].keys())\n",
    "        stage_tokens = [debug_data[\"tokens\"][\"stages\"][s][\"total\"] for s in stages]\n",
    "        \n",
    "        # Add a special \"databases\" entry if we have database token data\n",
    "        if db_token_count > 0:\n",
    "            stages.append(\"databases\")\n",
    "            stage_tokens.append(db_token_count)\n",
    "        \n",
    "        # Sort by token count\n",
    "        sorted_data = sorted(zip(stages, stage_tokens), key=lambda x: x[1], reverse=True)\n",
    "        stages = [s[0] for s in sorted_data]\n",
    "        stage_tokens = [s[1] for s in sorted_data]\n",
    "        \n",
    "        # Define colors\n",
    "        stage_colors = {\n",
    "            'router': '#4287f5',      # Blue\n",
    "            'clarifier': '#42f59e',   # Green\n",
    "            'planner': '#f5a742',     # Orange\n",
    "            'database_query': '#f54242', # Red\n",
    "            'judge': '#f5e642',       # Yellow\n",
    "            'summary': '#9e42f5',     # Purple\n",
    "            'databases': '#ff42a1',   # Pink for database tokens\n",
    "            'default': '#999999'      # Gray for unknown stages\n",
    "        }\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        bars = ax4.barh(\n",
    "            stages,\n",
    "            stage_tokens,\n",
    "            color=[stage_colors.get(s, stage_colors['default']) for s in stages],\n",
    "            height=0.6,\n",
    "            alpha=0.8,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5\n",
    "        )\n",
    "        \n",
    "        # Add token count and percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            percentage = (width / total_tokens) * 100\n",
    "            \n",
    "            ax4.text(\n",
    "                width + max(stage_tokens) * 0.02,\n",
    "                bar.get_y() + bar.get_height()/2,\n",
    "                f\"{int(width):,}\",\n",
    "                va='center',\n",
    "                ha='left',\n",
    "                fontsize=9,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "            \n",
    "            # Add percentage within the bar if wide enough\n",
    "            if width > max(stage_tokens) * 0.15:\n",
    "                ax4.text(\n",
    "                    width/2,\n",
    "                    bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{percentage:.1f}%\",\n",
    "                    va='center',\n",
    "                    ha='center',\n",
    "                    fontsize=9,\n",
    "                    fontweight='bold',\n",
    "                    color='white'\n",
    "                )\n",
    "    else:\n",
    "        # Simple prompt vs completion breakdown\n",
    "        labels = [\"Prompt\", \"Completion\"]\n",
    "        values = [prompt_tokens, completion_tokens]\n",
    "        colors = ['#f7a883', '#83c1f7']\n",
    "        \n",
    "        # Add a Database label if we have database tokens\n",
    "        if db_token_count > 0:\n",
    "            labels.append(\"Database\")\n",
    "            values.append(db_token_count)\n",
    "            colors.append('#ff42a1')  # Pink for database tokens\n",
    "            \n",
    "        bars = ax4.barh(\n",
    "            labels,\n",
    "            values,\n",
    "            color=colors,\n",
    "            height=0.6,\n",
    "            alpha=0.8,\n",
    "            edgecolor='black',\n",
    "            linewidth=0.5\n",
    "        )\n",1] for s in sorted_data]\n",
    "        \n",
    "        # Define colors\n",
    "        stage_colors = {\n",
    "            'router': '#4287f5',      # Blue\n",
    "            'clarifier': '#42f59e',   # Green\n",
    "            'planner': '#f5a742',     # Orange\n",
    "            'database_query': '#f54242', # Red\n",
    "            'judge': '#f5e642',       # Yellow\n",
    "            'summary': '#9e42f5',     # Purple\n",
    "            'databases': '#ff42a',   # Pink for database tokens\n",
    "            'default': '#999999'      # Gray for unknown stages\n",
    "        }\n",
    "        \n",
    "        # Create horizontal bar chart\n",
    "        bars = ax4.barh(\n",
    "            stages,\n",
    "            stage_tokens,\n",
    "            color=[stage_colors.get(s, stage_colors['default') s instage],\n",
    "            height=0.6,\n",
    "            alpha=0.8,\n",
    "            edgecolor='black',\n",
    "           linewdth=0.5\n",
    "        )\n",
    "        \n",
    "        # Add token count and percetagelabel\n",
    "        fr i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            pecentage = (width / total_tokens) * 100\n",
    "            \n",
    "            ax4.xt(\n",
    "                with + max(stage_tokens) * 0.02,\n",
    "                bar.get_y() + bar.getheight()/2,\n",
    "                f\"{int(with):,}\",\n",
    "                v='cener',\n",
    "                h='left',\n",
    "                fontsize=9,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "            \n",
    "            # Add percentage within the bar if wide enough\n",
    "            if width > max(stage_tokens) * 0.15:\n",
    "                ax4.text(\n",
    "                    width/2,\n",
    "                    bar.get_y() + bar.get_height()/2,\n",
    "                    f\"{percentage:.1f}%\",\n",
    "                    va='center',\n",
    "                    ha='center',\n",
    "                    fontsize=9,\n",
    "                    fontweight='bold',\n",
    "                    color='white'\n",
    "                )\n",
    "    else:\n",
    "        # Simple prompt vs completion breakdown\n",
    "        labels = [\"Prompt\", \"Completion\"]\n",
    "        values = [prompt_tokens, completion_tokens]\n",
    "        colors = ['#f7a883', '#83c1f7'
    "        \n",
    "        # Add a Database label if we have database tokens\n",
    "        if db_token_count > 0:\n",
    "            labels.append(\"Aatabase\")\n",
    "            values.append(db_token_count)\n",
    "            colors.appdnd('#fd42a1')  # P nk for database tokens\n",
    "            \n",
    "        bars = ax4.barh(\n",
    "            labels,\n",
    "            values,\n",
    "            color=colors,\t",
    "            hoight=0.6,\n",
    "            alpha=0.8,\n",
    "           kedgeeolnr='black',\n",
    "             inewidth=0.5\n",
    "        )\n",
    "        \n",
    "        # Add token ccunt and peocentage labelunt and percentage labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            width = bar.get_width()\n",
    "            percentage = (width / total_tokens) * 100\n",
    "            \n",
    "            ax4.text(\n",
    "                width + max(values) * 0.02,\n",
    "                bar.get_y() + bar.get_height()/2,\n",
    "                f\"{int(width):,} ({percentage:.1f}%)\",\n",
    "                va='center',\n",
    "                ha='left',\n",
    "                fontsize=10,\n",
    "                fontweight='bold'\n",
    "            )\n",
    "    \n",
    "    ax4.set_title('Token Breakdown', fontsize=14, pad=20)\n",
    "    ax4.set_xlabel('Number of Tokens', fontsize=12)\n",
    "    ax4.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No performance metrics data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Token Usage Visualization\n",
    "if debug_data and \"tokens\" in debug_data:\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    \n",
    "    # Check if we have database token usage data\n",
    "    has_db_data = \"databases\" in debug_data[\"tokens\"] and debug_data[\"tokens\"][\"databases\"]\n",
    "    \n",
    "    if has_db_data:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.title(\"Database Token Usage\", fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Extract database token usage\n",
    "        db_usage = debug_data[\"tokens\"][\"databases\"]\n",
    "        \n",
    "        # Prepare dateft',\n",
    "                fontsiza=10,\n",
    "                 ontweighf=obold'\n"r
    "            ) visualization\n",
    "    \n",
    "    ax4.set_title('Token Breakdown', fontsize=14, pad=20)\n",
   d"b_naax4.set_xlabel('NumbermofeTokens',s = list(db2)\n",
    "    ax4.grid(axis='x', linestyle='--', alpha=_.3)\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No performance metrics data available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database Token Usage Visualization\n",
    "if debug_data and \"tokens\" in debug_data:\n"u
    "    import matplotlib.pyplot as pltsage.keys())\n",
    "    import numpy as np\n",
    "    \n",
    "    # Check if we have database token usage data\n",
    "    has_db_data = \"databases\" in debug_data[\"tokens\"] and debug_data[\"tokens\"][\"databases\"]\n",
    "    \n",
    "    if has_db_data:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "    \n",plt.title(\"DatabaseTokenUsage\",fontsize=16,)\n",
    "        \n",
    "        # Extract database token usage\n",
    "        db_usage = debug_data["tokes\"][\databases\"]\n"
    "        \n",
 # G"e       # Prepare data for visualization\n",
    "        db_names = list(db_usage.keys()t\n",
    "         available databases for display names\n",
    "        # Get available databases for display names\n",
    "        from iris.src.global_prompts.database_statement import get_available_databases    from iris.src.global_prompts.database_statement import get_available_databases\n",
    "        available_dbs = get_available_databases()\n",
    "        display_names = [available_dbs.get(db, {}).get(\"name\", db) for db in db_names]\n",
    "            \n",
    "        # Extract token counts\n",
    "        prompt_tokens = [db_usage[db][\"prompt_tokens\"] for db in db_names]\n",
    "        completion_tokens = [db_usage[db][\"completion_tokens\"] for db in db_names]\n",
    "        total_tokens = [db_usage[db][\"total_tokens\"] for db in db_names]\n",
    "        costs = [db_usage[db][\"cost\"] for db in db_names]\n",
    "        \n",
    "        # If no data, handle empty case\n",
    "        if not db_names:\n",
    "            plt.text(0.5, 0.5, \"No database token usage data available\", \n",
    "                     ha='center', va='center', fontsize=14)\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "            print(\"Database tokens are being tracked but none were used in this session.\")\n",
    "        else:\n",
    "            # Create stacked bar chart\n",
    "            y_pos = np.arange(len(display_names))\n",
    "            width = 0.7\n",
    "            \n",
    "            # Plot the bars\n",
    "            bars1 = plt.barh(y_pos, prompt_tokens, width, color='#f7a883', label='Prompt Tokens')\n",
    "            bars2 = plt.barh(y_pos, completion_tokens, width, left=prompt_tokens, color='#83c1f7', label='Completion Tokens')\n",
    "            \n",
    "            # Add database names\n",
    "            plt.yticks(y_pos, display_names)\n",
    "            \n",
    "            # Add token counts\n",
    "            for i, (p_tokens, c_tokens) in enumerate(zip(prompt_tokens, completion_tokens)):\n",
    "                total = p_tokens + c_tokens\n",
    "                if total > 0:\n",
    "                    plt.text(\n",
    "                        total + max(total_tokens) * 0.02 if max(total_tokens) > 0 else 5,\n",
    "                        i,\n",
    "                        f\"{int(total):,} tokens (${costs[i]:.8f})\",\n",
    "                        va='center',\n",
    "                        ha='left',\n",
    "                        fontsize=10,\n",
    "                        fontweight='bold'\n",
    "                    )\n",
    "                    \n",
    "                    # Add percentages within bars if wide enough\n",
    "                    if p_tokens > max(total_tokens) * 0.15 and p_tokens > 10:\n",
    "                        plt.text(\n",
    "                            p_tokens / 2,\n",
    "                            i,\n",
    "                            f\"{int(p_tokens):,}\",\n",
    "                            va='center',\n",
    "                            ha='center',\n",
    "                            fontsize=9,\n",
    "                            fontweight='bold'\n",
    "                        )\n",
    "                        \n",
    "                    if c_tokens > max(total_tokens) * 0.15 and c_tokens > 10:\n",
    "                        plt.text(\n",
    "                            p_tokens + c_tokens / 2,\n",
    "                            i,\n",
    "                            f\"{int(c_tokens):,}\",\n",
    "                            va='center',\n",
    "                            ha='center',\n",
    "                            fontsize=9,\n",
    "                            fontweight='bold'\n",
    "                        )\n",
    "            \n",
    "            # Add a summary annotation\n",
    "            total_db_tokens = sum(total_tokens)\n",
    "            total_db_cost = sum(costs)\n",
    "            \n",
    "            summary_text = (\n",
    "                f\"Total Database Tokens: {total_db_tokens:,}\\n\"\n",
    "                f\"Total Database Cost: ${total_db_cost:.8f}\"\n",
    "            )\n",
    "            \n",
    "            plt.annotate(\n",
    "                summary_text,\n",
    "                xy=(0.02, 0.97),\n",
    "                xycoords='axes fraction',\n",
    "                va='top',\n",
    "                ha='left',\n",
    "                fontsize=11,\n",
    "                bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"white\", edgecolor=\"black\", alpha=0.9)\n",
    "            )\n",
    "            \n",
    "            # Add legend and labels\n",
    "            plt.legend(loc='lower right')\n",
    "            plt.xlabel('Number of Tokens', fontsize=12)\n",
    "            plt.grid(axis='x', linestyle='--', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Create a detailed table view\n",
    "            plt.figure(figsize=(10, 4))\n",
    "            plt.axis('off')\n",
    "            plt.title(\"Database Token Usage Details\", fontsize=14, fontweight='bold')\n",
    "            \n",
    "            # Create table data\n",
    "            table_data = []\n",
    "            for i, name in enumerate(display_names):\n",
    "                table_data.append([\n",
    "                    name,\n",
    "                    f\"{prompt_tokens[i]:,}\",\n",
    "                    f\"{completion_tokens[i]:,}\",\n",
    "                    f\"{total_tokens[i]:,}\",\n",
    "                    f\"${costs[i]:.8f}\"\n",
    "                ])\n",
    "            \n",
    "            # Add a total row\n",
    "            table_data.append([\n",
    "                \"TOTAL\",\n",
    "                f\"{sum(prompt_tokens):,}\",\n",
    "                f\"{sum(completion_tokens):,}\",\n",
    "                f\"{sum(total_tokens):,}\",\n",
    "                f\"${sum(costs):.8f}\"\n",
    "            ])\n",
    "            \n",
    "            # Create and configure table\n",
    "            table = plt.table(\n",
    "                cellText=table_data,\n",
    "                colLabels=[\"Database\", \"Prompt Tokens\", \"Completion Tokens\", \"Total Tokens\", \"Cost\"],\n",
    "                loc='center',\n",
    "                cellLoc='center'\n",
    "            )\n",
    "            \n",
    "            # Style the table\n",
    "            table.auto_set_font_size(False)\n",
    "            table.set_fontsize(10)\n",
    "            table.scale(1, 1.5)\n",
    "            \n",
    "            # Highlight header and total rows\n",
    "            for i, key in enumerate(table._cells):\n",
    "                cell = table._cells[key]\n",
    "                if key[0] == 0:  # Header row\n",
    "                    cell.set_text_props(fontweight='bold')\n",
    "                    cell.set_facecolor('#e0e0e0')\n",
    "                elif key[0] == len(table_data):  # Total row\n",
    "                    cell.set_text_props(fontweight='bold')\n",
    "                    cell.set_facecolor('#f0f0f0')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No database token usage data found in debug information. Check if database tokens are being tracked correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
